{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bsobj=BeautifulSoup(html.read())\n",
    "print(bsobj.h1)     # or bsobj.html.body.h1     , bsobj.body.h1     , bsobj.html.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connecting Reliably\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "    #return null, break, or do some other \"Plan B\"\n",
    "else:\n",
    "    '''program continues. Note: If you return or break in\n",
    "    exception catch, you do not need to use the \"else\" statement'''\n",
    "    \n",
    "'''\n",
    "If HTTP error code is returned, program now prints the error and does not execute\n",
    "the rest of the program under the else statement.\n",
    "\n",
    "If server not found, urlopen will output URLError. (No servers could be reached)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It Worked!\n"
     ]
    }
   ],
   "source": [
    "# addtion with URLError\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(\"It Worked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\element.py:1050: UserWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead.\n",
      "  tag_name, tag_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnonExistentTag is a made-up tag, not a BS function.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check tag exist in hmtl source code\n",
    "print(bsobj.nonExistentTag)\n",
    "\n",
    "'''\n",
    "nonExistentTag is a made-up tag, not a BS function.\n",
    "it grabs the first occurrence of 'nonExistentTag' on the page\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\element.py:1050: UserWarning: .nonExistentTag is deprecated, use .find(\"nonExistent\") instead.\n",
      "  tag_name, tag_name))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'someTag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8d41fdbc33a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonExistentTag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msomeTag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'someTag'"
     ]
    }
   ],
   "source": [
    "print(bsobj.nonExistentTag.someTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag was not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\bs4\\element.py:1050: UserWarning: .nonExistingTag is deprecated, use .find(\"nonExisting\") instead.\n",
      "  tag_name, tag_name))\n"
     ]
    }
   ],
   "source": [
    "# Check for both situations\n",
    "try:\n",
    "    badContent = bsobj.nonExistingTag.anotherTag\n",
    "except AttributeError as e:\n",
    "    print(\"Tag was not found\")\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print(\"Tag was not found\")\n",
    "    else:\n",
    "        print(badContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# exactly the same as scrapper written in another way\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsobj = BeautifulSoup(html.read(), 'html.parser')     # can disregard optional arg 'html.parser'\n",
    "        title = bsobj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
